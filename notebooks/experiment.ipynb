{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This repo is based on the paper [Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to Tokens](https://arxiv.org/pdf/1805.02214.pdf) by Marek Rei and Anders SÃ¸gaard. The original code repositary can be found [here](https://github.com/marekrei/mltagger)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To begin, train the model with experiment.py where it takes in a configuration file that contains the necessary hyperparameters and file paths. The script is dependent on two other files ([model.py](https://github.com/DerekChia/mltagger/blob/master/src/model.py) and [evaluator.py](https://github.com/DerekChia/mltagger/blob/master/src/evaluator.py)) where the MLTModel and MLTEvaluator objects are initialised and updated during runtime. Since we are using Jupyter Notebook, these two files are imported using model.ipynb and evaluator.ipynb.\n",
    "\n",
    "Reference: [src/experiment.py](https://github.com/DerekChia/mltagger/blob/master/src/experiment.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.ipynb\n",
    "%run evaluator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    import ConfigParser as configparser\n",
    "except:\n",
    "    import configparser\n",
    "\n",
    "# Replaced by %run model.ipynb and evaluator.ipynb\n",
    "# from model import MLTModel\n",
    "# from evaluator import MLTEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_input_files(file_paths, max_sentence_length=-1) return *sentences*\n",
    "\n",
    "- parse_config(config_section, config_path) return *config*\n",
    "\n",
    "- is_float(value) return *{True, False}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_input_files\n",
    "This function takes in the input file(s) path and return sentences in the following format. Note that the input files are expected to be in TSV format, CoNLL style.\n",
    "\n",
    ">sentence = [['Not', 'c'], ['only', 'c'], ['as', 'c'], ['a', 'c'], ['hobby', 'c'], ['.', 'c']]\n",
    "\n",
    ">sentences = [\n",
    "> [['Not', 'c'], ['only', 'c'], ['as', 'c'], ['a', 'c'], ['hobby', 'c'], ['.', 'c']],\n",
    "> [['They', 'c'], ['use', 'c'], ['computers', 'c'], ['for', 'c'], ['their', 'c'], ['works', 'i'], ['.', 'c']]\n",
    ">]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_files(file_paths, max_sentence_length=-1):\n",
    "    \"\"\"\n",
    "    Reads input files in whitespace-separated format.\n",
    "    Will split file_paths on comma, reading from multiple files.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    line_length = None\n",
    "    # file_path might contain multiple files, split them and iterate through\n",
    "    for file_path in file_paths.strip().split(\",\"):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            sentence = []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                # Ensure that line contains character, else this is an indicator for newline\n",
    "                if len(line) > 0:\n",
    "                    line_parts = line.split()\n",
    "                    # Check if input file has both word and label\n",
    "                    # Might not be a necessary check during inference since \n",
    "                    # input may not have a ground truth (second column)\n",
    "                    # assert(len(line_parts) >= 2), line\n",
    "                    # assert(len(line_parts) == line_length or line_length == None)\n",
    "                    # line_length = len(line_parts)\n",
    "                    sentence.append(line_parts)\n",
    "                # If line has no character (i.e. empty) and length of previous sentence is more than zero,\n",
    "                # push the previous sentence into the sentences list and anticipate new sentence.\n",
    "                elif len(line) == 0 and len(sentence) > 0:\n",
    "                    if max_sentence_length <= 0 or len(sentence) <= max_sentence_length:\n",
    "                        sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            # Not in use\n",
    "            if len(sentence) > 0:\n",
    "                if max_sentence_length <= 0 or len(sentence) <= max_sentence_length:\n",
    "                    sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse_config\n",
    "This function reads configuration from the input `config_path` and returns a dictionary where it tries to guess the correct datatype for each config value. `config_section` is used as a starting key [config]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config_section, config_path):\n",
    "    \"\"\"\n",
    "    Reads configuration from the file and returns a dictionary.\n",
    "    Tries to guess the correct datatype for each of the config values.\n",
    "    \"\"\"\n",
    "    config_parser = configparser.SafeConfigParser(allow_no_value=True)\n",
    "    config_parser.read(config_path)\n",
    "    config = collections.OrderedDict()\n",
    "    for key, value in config_parser.items(config_section):\n",
    "        if value is None or len(value.strip()) == 0:\n",
    "            config[key] = None\n",
    "        elif value.lower() in [\"true\", \"false\"]:\n",
    "            config[key] = config_parser.getboolean(config_section, key)\n",
    "        elif value.isdigit():\n",
    "            config[key] = config_parser.getint(config_section, key)\n",
    "        elif is_float(value):\n",
    "            config[key] = config_parser.getfloat(config_section, key)\n",
    "        else:\n",
    "            config[key] = config_parser.get(config_section, key)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_float\n",
    "This function checks if the parameter is of type float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(value):\n",
    "    \"\"\"\n",
    "    Check in value is of type float()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_batches_of_sentence_ids\n",
    "Based on the input parameters:\n",
    "\n",
    "- If `batch_equal_size` is `True`, group sentences into batches by IDs based on their length, according to a limit of `max_batch_size`. For example, if there are 64 sentences with length 10 (i.e. 64 sentences each with 10 characters in total) and `max_batch_size` is set to `32`, these 64 sentences will be batched together into 2 batches.\n",
    "    ```\n",
    "    Example:\n",
    "    Length of each sentence, [ID of each sentence]\n",
    "    10, [   [0, ... , 31]\n",
    "    10,     [32, ... , 63]\n",
    "    25,     [2553, 2680]\n",
    "    43,     [142, 305, 1490, 1775, 1973]\n",
    "    27,     [194, 197, 245, 348, 359]\n",
    "    XX,     [...]    ]\n",
    "    ```\n",
    "- If `batch_equal_size` is `False`, each batch will contain a fixed number of sentences (`max_batch_size`).\n",
    "    ```\n",
    "    Example:\n",
    "    [ID of each sentence]\n",
    "    [\n",
    "        [0, 1, 2, 3, 4]\n",
    "        [5, 6, 7, 8, 9]\n",
    "        [10, 11, 12, 13, 14]\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "Return: \n",
    "- List of lists with sentences ids.\n",
    "\n",
    "Default value:\n",
    "- `batch_equal_size` = `True`\n",
    "- `max_batch_size` = `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches_of_sentence_ids(sentences, batch_equal_size, max_batch_size):\n",
    "    \"\"\"\n",
    "    Groups together sentences into batches\n",
    "    If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
    "    If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
    "    Returns a list of lists with sentences ids.\n",
    "    \"\"\"\n",
    "    if batch_equal_size == True:\n",
    "        sentence_ids_by_length = collections.OrderedDict()\n",
    "        for _id, sentence in enumerate(sentences):\n",
    "            length = len(sentence)\n",
    "            if length not in sentence_ids_by_length:\n",
    "                sentence_ids_by_length[length] = []\n",
    "                sentence_ids_by_length[length].append(_id)\n",
    "            else:\n",
    "                sentence_ids_by_length[length].append(_id)\n",
    "        # Fitting each batch to the size defined in max_batch_size\n",
    "        for sentence_length in sentence_ids_by_length:\n",
    "            for i in range(0, len(sentence_ids_by_length[sentence_length]), max_batch_size):\n",
    "                batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i : i + max_batch_size])\n",
    "    else:\n",
    "        batch = []\n",
    "        for i in range(len(sentences)):\n",
    "            if len(batch) != max_batch_size:\n",
    "                batch.append(i)\n",
    "            else:\n",
    "                batches_of_sentence_ids.append(batch)\n",
    "                batch = []\n",
    "                batch.append(i)\n",
    "    return batches_of_sentence_ids\n",
    "\n",
    "\"\"\"Original Code Below\"\"\"\n",
    "#     batches_of_sentence_ids = []\n",
    "#     if batch_equal_size == True:\n",
    "#         sentence_ids_by_length = collections.OrderedDict()\n",
    "#         sentence_length_sum = 0.0\n",
    "#         for i in range(len(sentences)):\n",
    "#             length = len(sentences[i])\n",
    "#             if length not in sentence_ids_by_length:\n",
    "#                 sentence_ids_by_length[length] = []\n",
    "#             sentence_ids_by_length[length].append(i)\n",
    "\n",
    "#         for sentence_length in sentence_ids_by_length:\n",
    "#             if max_batch_size > 0:\n",
    "#                 batch_size = max_batch_size\n",
    "#             else:\n",
    "#                 batch_size = int((-1 * max_batch_size) / sentence_length)\n",
    "\n",
    "#             for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
    "#                 batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
    "#     else:\n",
    "#         current_batch = []\n",
    "#         max_sentence_length = 0\n",
    "#         for i in range(len(sentences)):\n",
    "#             current_batch.append(i)\n",
    "#             if len(sentences[i]) > max_sentence_length:\n",
    "#                 max_sentence_length = len(sentences[i])\n",
    "#             if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
    "#               or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
    "#                 batches_of_sentence_ids.append(current_batch)\n",
    "#                 current_batch = []\n",
    "#                 max_sentence_length = 0\n",
    "#         if len(current_batch) > 0:\n",
    "#             batches_of_sentence_ids.append(current_batch)\n",
    "#     return batches_of_sentence_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_sentences\n",
    "\n",
    "Function processes all sentences with evaluator object and return evaluation metrics. Function will trigger `process_batch` function by feeding in batch of sentences and learning rate configured.\n",
    "\n",
    "Return:\n",
    "- evaluator object with results populated\n",
    "\n",
    "Default value:\n",
    "- `garbage_collection` = `False`\n",
    "- `batch_equal_size` = `True`\n",
    "- `max_batch_size` = `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentences(epoch, data, model, is_training, learningrate, config, name):\n",
    "    \"\"\"\n",
    "    Process all the sentences with the labeler, return evaluation metrics.\n",
    "    \"\"\"\n",
    "    evaluator = MLTEvaluator(config)\n",
    "    \n",
    "    # From data, create batches of sentences ids based batch_equal_size flag.\n",
    "    # batch_equal_size = False, max_batch_size = 32\n",
    "    batches_of_sentence_ids = create_batches_of_sentence_ids(data, config[\"batch_equal_size\"], config[\"max_batch_size\"])\n",
    "    \n",
    "    # Randomly shuffle data AGAIN if this is training data. \n",
    "    # Question: Why shuffle again when data_train was shuffled in run_experiment() before this?\n",
    "    # See random.shuffle(data_train)\n",
    "    if is_training == True:\n",
    "        random.shuffle(batches_of_sentence_ids)\n",
    "    \n",
    "    # sentence_ids_in_batch refers to each batch of sentence_ids\n",
    "    # E.g. sentence_ids_in_batch = [10, 11, 12, 13, 14]\n",
    "    for count, sentence_ids_in_batch in enumerate(batches_of_sentence_ids):        \n",
    "        # Build batch from data. Each batch now contains sentences (not ID)\n",
    "        # For every sentence ID (i) in sentence_ids, get the actual sentence data[i]\n",
    "        # batch = [\n",
    "        # [['Not', 'c'], ['only', 'c'], ['as', 'c'], ['a', 'c'], ['hobby', 'c'], ['.', 'c']], # First sentence\n",
    "        # [['They', 'c'], ['use', 'c'], ['computers', 'c'], ['for', 'c'], ['their', 'c'], ['works', 'i'], ['.', 'c']] # Second sentence\n",
    "        #]\n",
    "        batch = [data[i] for i in sentence_ids_in_batch]\n",
    "        \n",
    "        # Get cost, predicted labels and probs for each batch\n",
    "        print('############### Epoch', epoch + 1,'Batch', count + 1, 'of', len(batches_of_sentence_ids) , '###############')\n",
    "        cost, sentence_scores, token_scores_list = model.process_batch(batch, is_training, learningrate)\n",
    "        \n",
    "        # Append cost, predicted labels and probs to the evaluator object\n",
    "        evaluator.append_data(cost, batch, sentence_scores, token_scores_list)\n",
    "    \n",
    "        # Not in use. garbage_collection defaults to False.\n",
    "        while config[\"garbage_collection\"] == True and gc.collect() > 0:\n",
    "            pass\n",
    "\n",
    "        results = evaluator.get_results(name)\n",
    "        for key in results:\n",
    "            print(key + \": \" + str(results[key]))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: The SafeConfigParser class has been renamed to ConfigParser in Python 3.2. This alias will be removed in future versions. Use ConfigParser directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_words: 13470\n",
      "n_chars: 97\n",
      "n_singletons: 7078\n",
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From <ipython-input-1-924ae6f31412>:311: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "n_preloaded_embeddings: 9469\n",
      "parameter_count: 5934452\n",
      "parameter_count_without_word_embeddings: 1893452\n",
      "EPOCH: 0\n",
      "current_learningrate: 1.0\n",
      "############### Epoch 1 Batch 1 of 898 ###############\n",
      "train_cost_avg: 0.29047760367393494\n",
      "train_cost_sum: 9.295283317565918\n",
      "train_sentence_count: 32.0\n",
      "train_sentence_predicted: 9.0\n",
      "train_sentence_correct: 7.0\n",
      "train_sentence_total: 26.0\n",
      "train_sentence_precision: 0.7777777777777778\n",
      "train_sentence_recall: 0.7777777777777778\n",
      "train_sentence_f1_score: 0.7777777777777778\n",
      "train_sentence_f05_score: 0.7777777777777778\n",
      "train_sentence_correct_binary: 11.0\n",
      "train_sentence_accuracy_binary: 0.34375\n",
      "train_tok_0_map: 0.41046325052984306\n",
      "train_tok_0_p: 0.16444444444444445\n",
      "train_tok_0_r: 0.44047619047619047\n",
      "train_tok_0_f: 0.2394822006472492\n",
      "train_tok_0_f05: 0.1880081300813008\n",
      "train_time: 3.3096811771392822\n",
      "############### Epoch 1 Batch 2 of 898 ###############\n",
      "train_cost_avg: 0.2614518776535988\n",
      "train_cost_sum: 16.732920169830322\n",
      "train_sentence_count: 64.0\n",
      "train_sentence_predicted: 39.0\n",
      "train_sentence_correct: 24.0\n",
      "train_sentence_total: 43.0\n",
      "train_sentence_precision: 0.6153846153846154\n",
      "train_sentence_recall: 0.6153846153846154\n",
      "train_sentence_f1_score: 0.6153846153846154\n",
      "train_sentence_f05_score: 0.6153846153846154\n",
      "train_sentence_correct_binary: 30.0\n",
      "train_sentence_accuracy_binary: 0.46875\n",
      "train_tok_0_map: 0.36974220108245964\n",
      "train_tok_0_p: 0.15330188679245282\n",
      "train_tok_0_r: 0.45774647887323944\n",
      "train_tok_0_f: 0.2296819787985866\n",
      "train_tok_0_f05: 0.17682263329706202\n",
      "train_time: 4.47597599029541\n",
      "############### Epoch 1 Batch 3 of 898 ###############\n",
      "train_cost_avg: 0.2365033725897471\n",
      "train_cost_sum: 22.704323768615723\n",
      "train_sentence_count: 96.0\n",
      "train_sentence_predicted: 70.0\n",
      "train_sentence_correct: 47.0\n",
      "train_sentence_total: 66.0\n",
      "train_sentence_precision: 0.6714285714285714\n",
      "train_sentence_recall: 0.6714285714285714\n",
      "train_sentence_f1_score: 0.6714285714285714\n",
      "train_sentence_f05_score: 0.6714285714285714\n",
      "train_sentence_correct_binary: 54.0\n",
      "train_sentence_accuracy_binary: 0.5625\n",
      "train_tok_0_map: 0.3543650671392383\n",
      "train_tok_0_p: 0.1543859649122807\n",
      "train_tok_0_r: 0.38596491228070173\n",
      "train_tok_0_f: 0.22055137844611528\n",
      "train_tok_0_f05: 0.17543859649122806\n",
      "train_time: 5.841153860092163\n",
      "############### Epoch 1 Batch 4 of 898 ###############\n",
      "train_cost_avg: 0.2231154665350914\n",
      "train_cost_sum: 28.5587797164917\n",
      "train_sentence_count: 128.0\n",
      "train_sentence_predicted: 101.0\n",
      "train_sentence_correct: 69.0\n",
      "train_sentence_total: 88.0\n",
      "train_sentence_precision: 0.6831683168316832\n",
      "train_sentence_recall: 0.6831683168316832\n",
      "train_sentence_f1_score: 0.6831683168316832\n",
      "train_sentence_f05_score: 0.6831683168316831\n",
      "train_sentence_correct_binary: 77.0\n",
      "train_sentence_accuracy_binary: 0.6015625\n",
      "train_tok_0_map: 0.3574810221946777\n",
      "train_tok_0_p: 0.14859437751004015\n",
      "train_tok_0_r: 0.3501577287066246\n",
      "train_tok_0_f: 0.20864661654135336\n",
      "train_tok_0_f05: 0.1679273827534039\n",
      "train_time: 7.200706958770752\n",
      "############### Epoch 1 Batch 5 of 898 ###############\n",
      "train_cost_avg: 0.2269614815711975\n",
      "train_cost_sum: 36.3138370513916\n",
      "train_sentence_count: 160.0\n",
      "train_sentence_predicted: 132.0\n",
      "train_sentence_correct: 87.0\n",
      "train_sentence_total: 106.0\n",
      "train_sentence_precision: 0.6590909090909091\n",
      "train_sentence_recall: 0.6590909090909091\n",
      "train_sentence_f1_score: 0.6590909090909091\n",
      "train_sentence_f05_score: 0.6590909090909091\n",
      "train_sentence_correct_binary: 96.0\n",
      "train_sentence_accuracy_binary: 0.6\n",
      "train_tok_0_map: 0.36192355888225985\n",
      "train_tok_0_p: 0.1524822695035461\n",
      "train_tok_0_r: 0.3200992555831266\n",
      "train_tok_0_f: 0.20656525220176142\n",
      "train_tok_0_f05: 0.17031951412727753\n",
      "train_time: 9.969726085662842\n",
      "############### Epoch 1 Batch 6 of 898 ###############\n",
      "train_cost_avg: 0.21842345595359802\n",
      "train_cost_sum: 41.93730354309082\n",
      "train_sentence_count: 192.0\n",
      "train_sentence_predicted: 162.0\n",
      "train_sentence_correct: 110.0\n",
      "train_sentence_total: 129.0\n",
      "train_sentence_precision: 0.6790123456790124\n",
      "train_sentence_recall: 0.6790123456790124\n",
      "train_sentence_f1_score: 0.6790123456790124\n",
      "train_sentence_f05_score: 0.6790123456790124\n",
      "train_sentence_correct_binary: 121.0\n",
      "train_sentence_accuracy_binary: 0.6302083333333334\n",
      "train_tok_0_map: 0.36541478237416314\n",
      "train_tok_0_p: 0.16149732620320856\n",
      "train_tok_0_r: 0.3075356415478615\n",
      "train_tok_0_f: 0.21178120617110802\n",
      "train_tok_0_f05: 0.17844481210115812\n",
      "train_time: 11.207086086273193\n",
      "############### Epoch 1 Batch 7 of 898 ###############\n",
      "train_cost_avg: 0.2255984672478267\n",
      "train_cost_sum: 50.534056663513184\n",
      "train_sentence_count: 224.0\n",
      "train_sentence_predicted: 193.0\n",
      "train_sentence_correct: 127.0\n",
      "train_sentence_total: 146.0\n",
      "train_sentence_precision: 0.6580310880829016\n",
      "train_sentence_recall: 0.6580310880829016\n",
      "train_sentence_f1_score: 0.6580310880829016\n",
      "train_sentence_f05_score: 0.6580310880829016\n",
      "train_sentence_correct_binary: 139.0\n",
      "train_sentence_accuracy_binary: 0.6205357142857143\n",
      "train_tok_0_map: 0.35521466650159605\n",
      "train_tok_0_p: 0.15369649805447472\n",
      "train_tok_0_r: 0.2964352720450281\n",
      "train_tok_0_f: 0.20243433696348495\n",
      "train_tok_0_f05: 0.17007534983853606\n",
      "train_time: 12.514509916305542\n",
      "############### Epoch 1 Batch 8 of 898 ###############\n",
      "train_cost_avg: 0.22566493228077888\n",
      "train_cost_sum: 57.770222663879395\n",
      "train_sentence_count: 256.0\n",
      "train_sentence_predicted: 219.0\n",
      "train_sentence_correct: 142.0\n",
      "train_sentence_total: 162.0\n",
      "train_sentence_precision: 0.6484018264840182\n",
      "train_sentence_recall: 0.6484018264840182\n",
      "train_sentence_f1_score: 0.6484018264840182\n",
      "train_sentence_f05_score: 0.6484018264840182\n",
      "train_sentence_correct_binary: 159.0\n",
      "train_sentence_accuracy_binary: 0.62109375\n",
      "train_tok_0_map: 0.3500347002792907\n",
      "train_tok_0_p: 0.1463860933211345\n",
      "train_tok_0_r: 0.272108843537415\n",
      "train_tok_0_f: 0.1903628792385485\n",
      "train_tok_0_f05: 0.16129032258064516\n",
      "train_time: 13.728171825408936\n",
      "############### Epoch 1 Batch 9 of 898 ###############\n",
      "train_cost_avg: 0.22679024934768677\n",
      "train_cost_sum: 65.31559181213379\n",
      "train_sentence_count: 288.0\n",
      "train_sentence_predicted: 247.0\n",
      "train_sentence_correct: 159.0\n",
      "train_sentence_total: 181.0\n",
      "train_sentence_precision: 0.6437246963562753\n",
      "train_sentence_recall: 0.6437246963562753\n",
      "train_sentence_f1_score: 0.6437246963562753\n",
      "train_sentence_f05_score: 0.6437246963562752\n",
      "train_sentence_correct_binary: 178.0\n",
      "train_sentence_accuracy_binary: 0.6180555555555556\n",
      "train_tok_0_map: 0.34513459884391884\n",
      "train_tok_0_p: 0.14412024756852343\n",
      "train_tok_0_r: 0.25232198142414863\n",
      "train_tok_0_f: 0.18345526167698367\n",
      "train_tok_0_f05: 0.15764023210831724\n",
      "train_time: 14.73918890953064\n",
      "############### Epoch 1 Batch 10 of 898 ###############\n",
      "train_cost_avg: 0.22417192608118058\n",
      "train_cost_sum: 71.73501634597778\n",
      "train_sentence_count: 320.0\n",
      "train_sentence_predicted: 274.0\n",
      "train_sentence_correct: 179.0\n",
      "train_sentence_total: 202.0\n",
      "train_sentence_precision: 0.6532846715328468\n",
      "train_sentence_recall: 0.6532846715328468\n",
      "train_sentence_f1_score: 0.6532846715328468\n",
      "train_sentence_f05_score: 0.6532846715328466\n",
      "train_sentence_correct_binary: 202.0\n",
      "train_sentence_accuracy_binary: 0.63125\n",
      "train_tok_0_map: 0.3499193442536295\n",
      "train_tok_0_p: 0.14165261382799327\n",
      "train_tok_0_r: 0.2291950886766712\n",
      "train_tok_0_f: 0.17509119332985934\n",
      "train_tok_0_f05: 0.15336863246302723\n",
      "train_time: 15.881459951400757\n",
      "############### Epoch 1 Batch 11 of 898 ###############\n",
      "train_cost_avg: 0.22421333464709195\n",
      "train_cost_sum: 78.92309379577637\n",
      "train_sentence_count: 352.0\n",
      "train_sentence_predicted: 304.0\n",
      "train_sentence_correct: 198.0\n",
      "train_sentence_total: 222.0\n",
      "train_sentence_precision: 0.6513157894736842\n",
      "train_sentence_recall: 0.6513157894736842\n",
      "train_sentence_f1_score: 0.6513157894736842\n",
      "train_sentence_f05_score: 0.6513157894736843\n",
      "train_sentence_correct_binary: 222.0\n",
      "train_sentence_accuracy_binary: 0.6306818181818182\n",
      "train_tok_0_map: 0.3492375107658688\n",
      "train_tok_0_p: 0.1387987012987013\n",
      "train_tok_0_r: 0.21951219512195122\n",
      "train_tok_0_f: 0.1700646444554948\n",
      "train_tok_0_f05: 0.14981601541966008\n",
      "train_time: 18.326377868652344\n",
      "############### Epoch 1 Batch 12 of 898 ###############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cost_avg: 0.22219580536087355\n",
      "train_cost_sum: 85.32318925857544\n",
      "train_sentence_count: 384.0\n",
      "train_sentence_predicted: 334.0\n",
      "train_sentence_correct: 219.0\n",
      "train_sentence_total: 243.0\n",
      "train_sentence_precision: 0.655688622754491\n",
      "train_sentence_recall: 0.655688622754491\n",
      "train_sentence_f1_score: 0.655688622754491\n",
      "train_sentence_f05_score: 0.655688622754491\n",
      "train_sentence_correct_binary: 245.0\n",
      "train_sentence_accuracy_binary: 0.6380208333333334\n",
      "train_tok_0_map: 0.34401502092299463\n",
      "train_tok_0_p: 0.13725490196078433\n",
      "train_tok_0_r: 0.20933014354066987\n",
      "train_tok_0_f: 0.16579819990525818\n",
      "train_tok_0_f05: 0.1474056603773585\n",
      "train_time: 19.554715156555176\n",
      "############### Epoch 1 Batch 13 of 898 ###############\n",
      "train_cost_avg: 0.21886232839180872\n",
      "train_cost_sum: 91.04672861099243\n",
      "train_sentence_count: 416.0\n",
      "train_sentence_predicted: 362.0\n",
      "train_sentence_correct: 238.0\n",
      "train_sentence_total: 262.0\n",
      "train_sentence_precision: 0.6574585635359116\n",
      "train_sentence_recall: 0.6574585635359116\n",
      "train_sentence_f1_score: 0.6574585635359116\n",
      "train_sentence_f05_score: 0.6574585635359117\n",
      "train_sentence_correct_binary: 268.0\n",
      "train_sentence_accuracy_binary: 0.6442307692307693\n",
      "train_tok_0_map: 0.3461462104598528\n",
      "train_tok_0_p: 0.13677811550151975\n",
      "train_tok_0_r: 0.19715224534501644\n",
      "train_tok_0_f: 0.16150740242261105\n",
      "train_tok_0_f05: 0.1457017969888295\n",
      "train_time: 20.684809923171997\n",
      "############### Epoch 1 Batch 14 of 898 ###############\n",
      "train_cost_avg: 0.21885760767119272\n",
      "train_cost_sum: 98.04820823669434\n",
      "train_sentence_count: 448.0\n",
      "train_sentence_predicted: 389.0\n",
      "train_sentence_correct: 255.0\n",
      "train_sentence_total: 280.0\n",
      "train_sentence_precision: 0.6555269922879178\n",
      "train_sentence_recall: 0.6555269922879178\n",
      "train_sentence_f1_score: 0.6555269922879178\n",
      "train_sentence_f05_score: 0.6555269922879178\n",
      "train_sentence_correct_binary: 289.0\n",
      "train_sentence_accuracy_binary: 0.6450892857142857\n",
      "train_tok_0_map: 0.34128990026400113\n",
      "train_tok_0_p: 0.13427299703264095\n",
      "train_tok_0_r: 0.18488253319713993\n",
      "train_tok_0_f: 0.15556510528577566\n",
      "train_tok_0_f05: 0.1420499136713232\n",
      "train_time: 22.254963159561157\n",
      "############### Epoch 1 Batch 15 of 898 ###############\n",
      "train_cost_avg: 0.2172626495361328\n",
      "train_cost_sum: 104.28607177734375\n",
      "train_sentence_count: 480.0\n",
      "train_sentence_predicted: 416.0\n",
      "train_sentence_correct: 274.0\n",
      "train_sentence_total: 300.0\n",
      "train_sentence_precision: 0.6586538461538461\n",
      "train_sentence_recall: 0.6586538461538461\n",
      "train_sentence_f1_score: 0.6586538461538461\n",
      "train_sentence_f05_score: 0.6586538461538461\n",
      "train_sentence_correct_binary: 312.0\n",
      "train_sentence_accuracy_binary: 0.65\n",
      "train_tok_0_map: 0.33937302983288264\n",
      "train_tok_0_p: 0.13299044819985306\n",
      "train_tok_0_r: 0.17370441458733205\n",
      "train_tok_0_f: 0.15064502704952143\n",
      "train_tok_0_f05: 0.1395312981806969\n",
      "train_time: 24.107308864593506\n",
      "############### Epoch 1 Batch 16 of 898 ###############\n",
      "train_cost_avg: 0.21494420990347862\n",
      "train_cost_sum: 110.05143547058105\n",
      "train_sentence_count: 512.0\n",
      "train_sentence_predicted: 444.0\n",
      "train_sentence_correct: 295.0\n",
      "train_sentence_total: 322.0\n",
      "train_sentence_precision: 0.6644144144144144\n",
      "train_sentence_recall: 0.6644144144144144\n",
      "train_sentence_f1_score: 0.6644144144144144\n",
      "train_sentence_f05_score: 0.6644144144144143\n",
      "train_sentence_correct_binary: 336.0\n",
      "train_sentence_accuracy_binary: 0.65625\n",
      "train_tok_0_map: 0.336824007600665\n",
      "train_tok_0_p: 0.13135593220338984\n",
      "train_tok_0_r: 0.1665174574753805\n",
      "train_tok_0_f: 0.14686142913541259\n",
      "train_tok_0_f05: 0.1371479132871258\n",
      "train_time: 26.239261865615845\n",
      "############### Epoch 1 Batch 17 of 898 ###############\n",
      "train_cost_avg: 0.21181240940795226\n",
      "train_cost_sum: 115.22595071792603\n",
      "train_sentence_count: 544.0\n",
      "train_sentence_predicted: 471.0\n",
      "train_sentence_correct: 315.0\n",
      "train_sentence_total: 342.0\n",
      "train_sentence_precision: 0.6687898089171974\n",
      "train_sentence_recall: 0.6687898089171974\n",
      "train_sentence_f1_score: 0.6687898089171974\n",
      "train_sentence_f05_score: 0.6687898089171974\n",
      "train_sentence_correct_binary: 361.0\n",
      "train_sentence_accuracy_binary: 0.6636029411764706\n",
      "train_tok_0_map: 0.33384754720778764\n",
      "train_tok_0_p: 0.13179347826086957\n",
      "train_tok_0_r: 0.16412859560067683\n",
      "train_tok_0_f: 0.1461944235116805\n",
      "train_tok_0_f05: 0.1371994342291372\n",
      "train_time: 28.31543278694153\n",
      "############### Epoch 1 Batch 18 of 898 ###############\n",
      "train_cost_avg: 0.21244246678219902\n",
      "train_cost_sum: 122.36686086654663\n",
      "train_sentence_count: 576.0\n",
      "train_sentence_predicted: 496.0\n",
      "train_sentence_correct: 330.0\n",
      "train_sentence_total: 359.0\n",
      "train_sentence_precision: 0.6653225806451613\n",
      "train_sentence_recall: 0.6653225806451613\n",
      "train_sentence_f1_score: 0.6653225806451613\n",
      "train_sentence_f05_score: 0.6653225806451613\n",
      "train_sentence_correct_binary: 381.0\n",
      "train_sentence_accuracy_binary: 0.6614583333333334\n",
      "train_tok_0_map: 0.3326362020188482\n",
      "train_tok_0_p: 0.13161375661375663\n",
      "train_tok_0_r: 0.16271463614063778\n",
      "train_tok_0_f: 0.14552102376599638\n",
      "train_tok_0_f05: 0.13684500068766334\n",
      "train_time: 29.87597393989563\n",
      "############### Epoch 1 Batch 19 of 898 ###############\n",
      "train_cost_avg: 0.21062567594804263\n",
      "train_cost_sum: 128.0604109764099\n",
      "train_sentence_count: 608.0\n",
      "train_sentence_predicted: 523.0\n",
      "train_sentence_correct: 350.0\n",
      "train_sentence_total: 379.0\n",
      "train_sentence_precision: 0.6692160611854685\n",
      "train_sentence_recall: 0.6692160611854685\n",
      "train_sentence_f1_score: 0.6692160611854685\n",
      "train_sentence_f05_score: 0.6692160611854685\n",
      "train_sentence_correct_binary: 406.0\n",
      "train_sentence_accuracy_binary: 0.6677631578947368\n",
      "train_tok_0_map: 0.33407608673837363\n",
      "train_tok_0_p: 0.13289902280130292\n",
      "train_tok_0_r: 0.1518987341772152\n",
      "train_tok_0_f: 0.14176511466296038\n",
      "train_tok_0_f05: 0.1363089669918482\n",
      "train_time: 31.682193994522095\n",
      "############### Epoch 1 Batch 20 of 898 ###############\n",
      "train_cost_avg: 0.2104779936373234\n",
      "train_cost_sum: 134.70591592788696\n",
      "train_sentence_count: 640.0\n",
      "train_sentence_predicted: 545.0\n",
      "train_sentence_correct: 368.0\n",
      "train_sentence_total: 402.0\n",
      "train_sentence_precision: 0.6752293577981652\n",
      "train_sentence_recall: 0.6752293577981652\n",
      "train_sentence_f1_score: 0.6752293577981652\n",
      "train_sentence_f05_score: 0.6752293577981652\n",
      "train_sentence_correct_binary: 429.0\n",
      "train_sentence_accuracy_binary: 0.6703125\n",
      "train_tok_0_map: 0.3382669874620495\n",
      "train_tok_0_p: 0.13855799373040753\n",
      "train_tok_0_r: 0.15315315315315314\n",
      "train_tok_0_f: 0.1454904542462146\n",
      "train_tok_0_f05: 0.14125015978524863\n",
      "train_time: 32.98654508590698\n",
      "############### Epoch 1 Batch 21 of 898 ###############\n",
      "train_cost_avg: 0.21342958651837848\n",
      "train_cost_sum: 143.42468214035034\n",
      "train_sentence_count: 672.0\n",
      "train_sentence_predicted: 574.0\n",
      "train_sentence_correct: 384.0\n",
      "train_sentence_total: 418.0\n",
      "train_sentence_precision: 0.6689895470383276\n",
      "train_sentence_recall: 0.6689895470383276\n",
      "train_sentence_f1_score: 0.6689895470383276\n",
      "train_sentence_f05_score: 0.6689895470383277\n",
      "train_sentence_correct_binary: 448.0\n",
      "train_sentence_accuracy_binary: 0.6666666666666666\n",
      "train_tok_0_map: 0.34318690728251006\n",
      "train_tok_0_p: 0.13847967000589276\n",
      "train_tok_0_r: 0.1570855614973262\n",
      "train_tok_0_f: 0.14719699342311307\n",
      "train_tok_0_f05: 0.14183969097054563\n",
      "train_time: 34.28547406196594\n",
      "############### Epoch 1 Batch 22 of 898 ###############\n",
      "train_cost_avg: 0.21270457926121625\n",
      "train_cost_sum: 149.74402379989624\n",
      "train_sentence_count: 704.0\n",
      "train_sentence_predicted: 597.0\n",
      "train_sentence_correct: 401.0\n",
      "train_sentence_total: 440.0\n",
      "train_sentence_precision: 0.6716917922948074\n",
      "train_sentence_recall: 0.6716917922948074\n",
      "train_sentence_f1_score: 0.6716917922948074\n",
      "train_sentence_f05_score: 0.6716917922948074\n",
      "train_sentence_correct_binary: 469.0\n",
      "train_sentence_accuracy_binary: 0.6661931818181818\n",
      "train_tok_0_map: 0.3416575461630481\n",
      "train_tok_0_p: 0.1368909512761021\n",
      "train_tok_0_r: 0.15157353885677585\n",
      "train_tok_0_f: 0.14385857970131058\n",
      "train_tok_0_f05: 0.13959540991364014\n",
      "train_time: 35.38263702392578\n",
      "############### Epoch 1 Batch 23 of 898 ###############\n",
      "train_cost_avg: 0.20966626185437906\n",
      "train_cost_sum: 154.314368724823\n",
      "train_sentence_count: 736.0\n",
      "train_sentence_predicted: 625.0\n",
      "train_sentence_correct: 422.0\n",
      "train_sentence_total: 461.0\n",
      "train_sentence_precision: 0.6752\n",
      "train_sentence_recall: 0.6752\n",
      "train_sentence_f1_score: 0.6752\n",
      "train_sentence_f05_score: 0.6752\n",
      "train_sentence_correct_binary: 494.0\n",
      "train_sentence_accuracy_binary: 0.6711956521739131\n",
      "train_tok_0_map: 0.3393265809906136\n",
      "train_tok_0_p: 0.1420150053590568\n",
      "train_tok_0_r: 0.16247700797057021\n",
      "train_tok_0_f: 0.15155847869602515\n",
      "train_tok_0_f05: 0.14568444200109948\n",
      "train_time: 36.724984884262085\n",
      "############### Epoch 1 Batch 24 of 898 ###############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cost_avg: 0.20665803800026575\n",
      "train_cost_sum: 158.7133731842041\n",
      "train_sentence_count: 768.0\n",
      "train_sentence_predicted: 649.0\n",
      "train_sentence_correct: 444.0\n",
      "train_sentence_total: 485.0\n",
      "train_sentence_precision: 0.6841294298921418\n",
      "train_sentence_recall: 0.6841294298921418\n",
      "train_sentence_f1_score: 0.6841294298921418\n",
      "train_sentence_f05_score: 0.6841294298921418\n",
      "train_sentence_correct_binary: 522.0\n",
      "train_sentence_accuracy_binary: 0.6796875\n",
      "train_tok_0_map: 0.33546483941507066\n",
      "train_tok_0_p: 0.1393235739525492\n",
      "train_tok_0_r: 0.16187683284457477\n",
      "train_tok_0_f: 0.14975583288117197\n",
      "train_tok_0_f05: 0.14331706303873715\n",
      "train_time: 38.2524688243866\n",
      "############### Epoch 1 Batch 25 of 898 ###############\n",
      "train_cost_avg: 0.2073541921377182\n",
      "train_cost_sum: 165.88335371017456\n",
      "train_sentence_count: 800.0\n",
      "train_sentence_predicted: 676.0\n",
      "train_sentence_correct: 460.0\n",
      "train_sentence_total: 501.0\n",
      "train_sentence_precision: 0.6804733727810651\n",
      "train_sentence_recall: 0.6804733727810651\n",
      "train_sentence_f1_score: 0.6804733727810651\n",
      "train_sentence_f05_score: 0.6804733727810651\n",
      "train_sentence_correct_binary: 543.0\n",
      "train_sentence_accuracy_binary: 0.67875\n",
      "train_tok_0_map: 0.33356756992959447\n",
      "train_tok_0_p: 0.1344186046511628\n",
      "train_tok_0_r: 0.16476624857468644\n",
      "train_tok_0_f: 0.1480532786885246\n",
      "train_tok_0_f05: 0.13955959049642652\n",
      "train_time: 40.54411315917969\n",
      "############### Epoch 1 Batch 26 of 898 ###############\n",
      "train_cost_avg: 0.20660855105290046\n",
      "train_cost_sum: 171.89831447601318\n",
      "train_sentence_count: 832.0\n",
      "train_sentence_predicted: 700.0\n",
      "train_sentence_correct: 478.0\n",
      "train_sentence_total: 523.0\n",
      "train_sentence_precision: 0.6828571428571428\n",
      "train_sentence_recall: 0.6828571428571428\n",
      "train_sentence_f1_score: 0.6828571428571428\n",
      "train_sentence_f05_score: 0.6828571428571429\n",
      "train_sentence_correct_binary: 565.0\n",
      "train_sentence_accuracy_binary: 0.6790865384615384\n",
      "train_tok_0_map: 0.3315279757608163\n",
      "train_tok_0_p: 0.13191677733510404\n",
      "train_tok_0_r: 0.1639163916391639\n",
      "train_tok_0_f: 0.14618592102035813\n",
      "train_tok_0_f05: 0.1372765800626497\n",
      "train_time: 41.81236910820007\n",
      "############### Epoch 1 Batch 27 of 898 ###############\n",
      "train_cost_avg: 0.20697558643641295\n",
      "train_cost_sum: 178.8269066810608\n",
      "train_sentence_count: 864.0\n",
      "train_sentence_predicted: 723.0\n",
      "train_sentence_correct: 493.0\n",
      "train_sentence_total: 542.0\n",
      "train_sentence_precision: 0.681881051175657\n",
      "train_sentence_recall: 0.681881051175657\n",
      "train_sentence_f1_score: 0.681881051175657\n",
      "train_sentence_f05_score: 0.6818810511756569\n",
      "train_sentence_correct_binary: 585.0\n",
      "train_sentence_accuracy_binary: 0.6770833333333334\n",
      "train_tok_0_map: 0.3325738932391104\n",
      "train_tok_0_p: 0.1361737677527151\n",
      "train_tok_0_r: 0.1742383752004276\n",
      "train_tok_0_f: 0.15287221570926146\n",
      "train_tok_0_f05: 0.1423953874377566\n",
      "train_time: 43.8254599571228\n",
      "############### Epoch 1 Batch 28 of 898 ###############\n",
      "train_cost_avg: 0.20555473597986357\n",
      "train_cost_sum: 184.17704343795776\n",
      "train_sentence_count: 896.0\n",
      "train_sentence_predicted: 749.0\n",
      "train_sentence_correct: 515.0\n",
      "train_sentence_total: 567.0\n",
      "train_sentence_precision: 0.6875834445927904\n",
      "train_sentence_recall: 0.6875834445927904\n",
      "train_sentence_f1_score: 0.6875834445927904\n",
      "train_sentence_f05_score: 0.6875834445927905\n",
      "train_sentence_correct_binary: 610.0\n",
      "train_sentence_accuracy_binary: 0.6808035714285714\n",
      "train_tok_0_map: 0.3400522016262903\n",
      "train_tok_0_p: 0.14095315024232632\n",
      "train_tok_0_r: 0.17724733367191467\n",
      "train_tok_0_f: 0.15703037120359956\n",
      "train_tok_0_f05: 0.14697212162048345\n",
      "train_time: 45.159284830093384\n",
      "############### Epoch 1 Batch 29 of 898 ###############\n",
      "train_cost_avg: 0.20408552473989025\n",
      "train_cost_sum: 189.39136695861816\n",
      "train_sentence_count: 928.0\n",
      "train_sentence_predicted: 777.0\n",
      "train_sentence_correct: 536.0\n",
      "train_sentence_total: 589.0\n",
      "train_sentence_precision: 0.6898326898326899\n",
      "train_sentence_recall: 0.6898326898326899\n",
      "train_sentence_f1_score: 0.6898326898326899\n",
      "train_sentence_f05_score: 0.6898326898326899\n",
      "train_sentence_correct_binary: 634.0\n",
      "train_sentence_accuracy_binary: 0.6831896551724138\n",
      "train_tok_0_map: 0.3413857185541106\n",
      "train_tok_0_p: 0.14544767661503588\n",
      "train_tok_0_r: 0.18937530742744713\n",
      "train_tok_0_f: 0.16452991452991453\n",
      "train_tok_0_f05: 0.15252357182473655\n",
      "train_time: 46.85706901550293\n",
      "############### Epoch 1 Batch 30 of 898 ###############\n",
      "train_cost_avg: 0.20194796621799468\n",
      "train_cost_sum: 193.8700475692749\n",
      "train_sentence_count: 960.0\n",
      "train_sentence_predicted: 804.0\n",
      "train_sentence_correct: 558.0\n",
      "train_sentence_total: 611.0\n",
      "train_sentence_precision: 0.6940298507462687\n",
      "train_sentence_recall: 0.6940298507462687\n",
      "train_sentence_f1_score: 0.6940298507462687\n",
      "train_sentence_f05_score: 0.6940298507462688\n",
      "train_sentence_correct_binary: 661.0\n",
      "train_sentence_accuracy_binary: 0.6885416666666667\n",
      "train_tok_0_map: 0.3393360442503906\n",
      "train_tok_0_p: 0.14696370822853036\n",
      "train_tok_0_r: 0.19522673031026253\n",
      "train_tok_0_f: 0.16769167691676917\n",
      "train_tok_0_f05: 0.15460799879035306\n",
      "train_time: 48.154202938079834\n",
      "############### Epoch 1 Batch 31 of 898 ###############\n",
      "train_cost_avg: 0.20173221057461155\n",
      "train_cost_sum: 200.11835289001465\n",
      "train_sentence_count: 992.0\n",
      "train_sentence_predicted: 829.0\n",
      "train_sentence_correct: 575.0\n",
      "train_sentence_total: 629.0\n",
      "train_sentence_precision: 0.6936067551266586\n",
      "train_sentence_recall: 0.6936067551266586\n",
      "train_sentence_f1_score: 0.6936067551266586\n",
      "train_sentence_f05_score: 0.6936067551266587\n",
      "train_sentence_correct_binary: 684.0\n",
      "train_sentence_accuracy_binary: 0.6895161290322581\n",
      "train_tok_0_map: 0.3385475954630156\n",
      "train_tok_0_p: 0.14912868632707774\n",
      "train_tok_0_r: 0.20640074211502782\n",
      "train_tok_0_f: 0.17315175097276264\n",
      "train_tok_0_f05: 0.15789100198694295\n",
      "train_time: 49.45061111450195\n",
      "############### Epoch 1 Batch 32 of 898 ###############\n",
      "train_cost_avg: 0.20164358243346214\n",
      "train_cost_sum: 206.48302841186523\n",
      "train_sentence_count: 1024.0\n",
      "train_sentence_predicted: 848.0\n",
      "train_sentence_correct: 589.0\n",
      "train_sentence_total: 647.0\n",
      "train_sentence_precision: 0.6945754716981132\n",
      "train_sentence_recall: 0.6945754716981132\n",
      "train_sentence_f1_score: 0.6945754716981132\n",
      "train_sentence_f05_score: 0.6945754716981133\n",
      "train_sentence_correct_binary: 707.0\n",
      "train_sentence_accuracy_binary: 0.6904296875\n",
      "train_tok_0_map: 0.34042197668891133\n",
      "train_tok_0_p: 0.148124191461837\n",
      "train_tok_0_r: 0.20761559383499548\n",
      "train_tok_0_f: 0.17289543223858062\n",
      "train_tok_0_f05: 0.15712913407437903\n",
      "train_time: 50.682976961135864\n",
      "############### Epoch 1 Batch 33 of 898 ###############\n",
      "train_cost_avg: 0.20367982441728766\n",
      "train_cost_sum: 215.08589458465576\n",
      "train_sentence_count: 1056.0\n",
      "train_sentence_predicted: 875.0\n",
      "train_sentence_correct: 603.0\n",
      "train_sentence_total: 664.0\n",
      "train_sentence_precision: 0.6891428571428572\n",
      "train_sentence_recall: 0.6891428571428572\n",
      "train_sentence_f1_score: 0.6891428571428572\n",
      "train_sentence_f05_score: 0.6891428571428572\n",
      "train_sentence_correct_binary: 723.0\n",
      "train_sentence_accuracy_binary: 0.6846590909090909\n",
      "train_tok_0_map: 0.3396564289447313\n",
      "train_tok_0_p: 0.14731585518102372\n",
      "train_tok_0_r: 0.208572691117985\n",
      "train_tok_0_f: 0.1726723980245107\n",
      "train_tok_0_f05: 0.1565090523244247\n",
      "train_time: 52.45182776451111\n",
      "############### Epoch 1 Batch 34 of 898 ###############\n",
      "train_cost_avg: 0.20339733537505655\n",
      "train_cost_sum: 221.29630088806152\n",
      "train_sentence_count: 1088.0\n",
      "train_sentence_predicted: 890.0\n",
      "train_sentence_correct: 616.0\n",
      "train_sentence_total: 685.0\n",
      "train_sentence_precision: 0.6921348314606741\n",
      "train_sentence_recall: 0.6921348314606741\n",
      "train_sentence_f1_score: 0.6921348314606741\n",
      "train_sentence_f05_score: 0.6921348314606742\n",
      "train_sentence_correct_binary: 745.0\n",
      "train_sentence_accuracy_binary: 0.6847426470588235\n",
      "train_tok_0_map: 0.33786287168721185\n",
      "train_tok_0_p: 0.14661769207223752\n",
      "train_tok_0_r: 0.2053150450064295\n",
      "train_tok_0_f: 0.17107142857142857\n",
      "train_tok_0_f05: 0.15550938250762936\n",
      "train_time: 54.58175611495972\n",
      "############### Epoch 1 Batch 35 of 898 ###############\n",
      "train_cost_avg: 0.2039814782994134\n",
      "train_cost_sum: 228.45925569534302\n",
      "train_sentence_count: 1120.0\n",
      "train_sentence_predicted: 914.0\n",
      "train_sentence_correct: 632.0\n",
      "train_sentence_total: 703.0\n",
      "train_sentence_precision: 0.6914660831509847\n",
      "train_sentence_recall: 0.6914660831509847\n",
      "train_sentence_f1_score: 0.6914660831509847\n",
      "train_sentence_f05_score: 0.6914660831509847\n",
      "train_sentence_correct_binary: 767.0\n",
      "train_sentence_accuracy_binary: 0.6848214285714286\n",
      "train_tok_0_map: 0.33853488543399973\n",
      "train_tok_0_p: 0.14858970630997384\n",
      "train_tok_0_r: 0.21336116910229644\n",
      "train_tok_0_f: 0.1751799794309222\n",
      "train_tok_0_f05: 0.15819453903783048\n",
      "train_time: 56.45240378379822\n",
      "############### Epoch 1 Batch 36 of 898 ###############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cost_avg: 0.20547254011034966\n",
      "train_cost_sum: 236.7043662071228\n",
      "train_sentence_count: 1152.0\n",
      "train_sentence_predicted: 938.0\n",
      "train_sentence_correct: 645.0\n",
      "train_sentence_total: 718.0\n",
      "train_sentence_precision: 0.6876332622601279\n",
      "train_sentence_recall: 0.6876332622601279\n",
      "train_sentence_f1_score: 0.6876332622601279\n",
      "train_sentence_f05_score: 0.6876332622601279\n",
      "train_sentence_correct_binary: 786.0\n",
      "train_sentence_accuracy_binary: 0.6822916666666666\n",
      "train_tok_0_map: 0.3359478832234087\n",
      "train_tok_0_p: 0.1467915956842703\n",
      "train_tok_0_r: 0.2131958762886598\n",
      "train_tok_0_f: 0.17386917773667396\n",
      "train_tok_0_f05: 0.15654332949797128\n",
      "train_time: 58.10879898071289\n",
      "############### Epoch 1 Batch 37 of 898 ###############\n",
      "train_cost_avg: 0.20590850992782697\n",
      "train_cost_sum: 243.79567575454712\n",
      "train_sentence_count: 1184.0\n",
      "train_sentence_predicted: 952.0\n",
      "train_sentence_correct: 658.0\n",
      "train_sentence_total: 740.0\n",
      "train_sentence_precision: 0.6911764705882353\n",
      "train_sentence_recall: 0.6911764705882353\n",
      "train_sentence_f1_score: 0.6911764705882353\n",
      "train_sentence_f05_score: 0.6911764705882352\n",
      "train_sentence_correct_binary: 808.0\n",
      "train_sentence_accuracy_binary: 0.6824324324324325\n",
      "train_tok_0_map: 0.3346822100441405\n",
      "train_tok_0_p: 0.1454798331015299\n",
      "train_tok_0_r: 0.2117408906882591\n",
      "train_tok_0_f: 0.17246496290189614\n",
      "train_tok_0_f05: 0.1551928783382789\n",
      "train_time: 59.86800503730774\n",
      "############### Epoch 1 Batch 38 of 898 ###############\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bde0bfa24d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.conf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-bde0bfa24d37>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mresults_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_dev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-bde0bfa24d37>\u001b[0m in \u001b[0;36mprocess_sentences\u001b[0;34m(epoch, data, model, is_training, learningrate, config, name)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'############### Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_of_sentence_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'###############'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_ids_in_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_scores_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_scores_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-924ae6f31412>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(self, batch, is_training, learningrate)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_input_dictionary_for_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_scores\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(config_path):\n",
    "    config = parse_config(\"config\", config_path)\n",
    "    temp_model_path = config_path + \".model\"\n",
    "    if \"random_seed\" in config:\n",
    "        random.seed(config[\"random_seed\"])\n",
    "        numpy.random.seed(config[\"random_seed\"])\n",
    "\n",
    "    # To print everything in config - not needed for now\n",
    "    # for key, val in config.items():\n",
    "    #     print(str(key) + \": \" + str(val))\n",
    "\n",
    "    data_train, data_dev, data_test = None, None, None\n",
    "    if config[\"path_train\"] != None and len(config[\"path_train\"]) > 0:\n",
    "        data_train = read_input_files(config[\"path_train\"], config[\"max_train_sent_length\"])\n",
    "    if config[\"path_dev\"] != None and len(config[\"path_dev\"]) > 0:\n",
    "        data_dev = read_input_files(config[\"path_dev\"])\n",
    "    if config[\"path_test\"] != None and len(config[\"path_test\"]) > 0:\n",
    "        data_test = []\n",
    "        for path_test in config[\"path_test\"].strip().split(\":\"):\n",
    "            data_test += read_input_files(path_test)\n",
    "    \n",
    "    model = MLTModel(config)\n",
    "    model.build_vocabs(data_train, data_dev, data_test, config[\"preload_vectors\"])\n",
    "    model.construct_network()\n",
    "    model.initialize_session()\n",
    "    if config[\"preload_vectors\"] != None:\n",
    "        model.preload_word_embeddings(config[\"preload_vectors\"])\n",
    "\n",
    "    print(\"parameter_count: \" + str(model.get_parameter_count()))\n",
    "    print(\"parameter_count_without_word_embeddings: \" + str(model.get_parameter_count_without_word_embeddings()))\n",
    "\n",
    "    if data_train != None:\n",
    "        model_selector = config[\"model_selector\"].split(\":\")[0]\n",
    "        model_selector_type = config[\"model_selector\"].split(\":\")[1]\n",
    "        best_selector_value = 0.0\n",
    "        best_epoch = -1\n",
    "        learningrate = config[\"learningrate\"]\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            print(\"EPOCH: \" + str(epoch))\n",
    "            print(\"current_learningrate: \" + str(learningrate))\n",
    "            random.shuffle(data_train)\n",
    "\n",
    "            results_train = process_sentences(epoch, data_train, model, is_training=True, learningrate=learningrate, config=config, name=\"train\")\n",
    "\n",
    "            if data_dev != None:\n",
    "                results_dev = process_sentences(epoch, data_dev, model, is_training=False, learningrate=0.0, config=config, name=\"dev\")\n",
    "\n",
    "                if math.isnan(results_dev[\"dev_cost_sum\"]) or math.isinf(results_dev[\"dev_cost_sum\"]):\n",
    "                    raise ValueError(\"Cost is NaN or Inf. Exiting.\")\n",
    "\n",
    "                if (epoch == 0 or (model_selector_type == \"high\" and results_dev[model_selector] > best_selector_value) \n",
    "                               or (model_selector_type == \"low\" and results_dev[model_selector] < best_selector_value)):\n",
    "                    best_epoch = epoch\n",
    "                    best_selector_value = results_dev[model_selector]\n",
    "                    model.saver.save(model.session, temp_model_path, latest_filename=os.path.basename(temp_model_path)+\".checkpoint\")\n",
    "                print(\"best_epoch: \" + str(best_epoch))\n",
    "\n",
    "                if config[\"stop_if_no_improvement_for_epochs\"] > 0 and (epoch - best_epoch) >= config[\"stop_if_no_improvement_for_epochs\"]:\n",
    "                    break\n",
    "\n",
    "                if (epoch - best_epoch) > 3:\n",
    "                    learningrate *= config[\"learningrate_decay\"]\n",
    "\n",
    "            while config[\"garbage_collection\"] == True and gc.collect() > 0:\n",
    "                pass\n",
    "\n",
    "        if data_dev != None and best_epoch >= 0:\n",
    "            # loading the best model so far\n",
    "            model.saver.restore(model.session, temp_model_path)\n",
    "            os.remove(temp_model_path+\".checkpoint\")\n",
    "            os.remove(temp_model_path+\".data-00000-of-00001\")\n",
    "            os.remove(temp_model_path+\".index\")\n",
    "            os.remove(temp_model_path+\".meta\")\n",
    "\n",
    "    if config[\"save\"] is not None and len(config[\"save\"]) > 0:\n",
    "        model.save(config[\"save\"])\n",
    "\n",
    "    if config[\"path_test\"] is not None:\n",
    "        i = 0\n",
    "        for path_test in config[\"path_test\"].strip().split(\":\"):\n",
    "            data_test = read_input_files(path_test)\n",
    "            results_test = process_sentences(epoch, data_test, model, is_training=False, learningrate=0.0, config=config, name=\"test\"+str(i))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_experiment('config.conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
